INTRODUCTION

Frequently, a software development project requires crucial decisions at the outset that might heavily influence its success. The challenge lies in the timing of these initial decisions, as they must be made when the team has the least information about the context, scope and risks involved, insights that will be better collected later on.

This study presents a case in which a development team was tasked with resuming a previous project that had failed in the past. Significant bugs were discovered, and the original developers were unable to fix them. The new team was provided with the source code and some initial requirements, and they had to decide whether attempting to fix the bugs or rewriting the entire program from scratch.

What factors should they have considered? What would have been the best decision? Was there an objective decision to be made?

These are the questions we will endeavor to answer henceforth.


BACKGROUND

This section presents a brief explanation of the project studied and challenges faced. The following description is a summarization extracted from the Requirements Document produced in partnership with the sponsors.


DCM UPLOADER

DCM Uploader is an application that makes it easier and safer to share medical images between hospitals and clinics using the DICOM protocol over the internet. It should allow the user to set routes between nodes to which the studies must be automatically sent. The final goal is to make exam images available accross many points, wherever the doctors, technichians and patients need them.

Each LAN wether inside a hospital, clinic or diagnosing center could have DCM Uploader installed in a centralized host (aka gateway), which is reponsible for recieving DICOM studies produced in many modalities such as Magnetic Resonance Imaging (MRI), X-Rays machines, Computed Tomography Scanners (CT scan) and so on. The Gateway's job is simply forwarding the studies received to the next connected Gateway. It must not store locally the studies for longer than strictly needed to make sure that all connected recipiants have received them. Also, the Gateways need to establish a secure channel to exchange the files, such as VPN, as sensitive data will travel through the internet.

After recieving studies from a neighbor Gateway (located in another LAN), it's optional (may be configured) to also forward the studies to a local PACS (Picture Archiving and Communication System), using DICOM protocol, in order to persist them and/or integrate with other DICOM programs. The PACS must be installed in the LAN but isn't part of DCM Uploader. Any DICOM compatible PACS can be used for that purposed, such as Orthanc or DCM4Chee.

The users of DCM Uploader are often the Hospital/Clinic Network Manager who would authenticate, setup the Gateways and local PACS and connect them using a graphical user interface. They will also monitor the health of the Gateways and consult transfer logs.

Other minor requirements have been identified but they are less relevant to this case study. The full Requirements Document can be found in [] (original in portuguese).


THE CASE

At first glence, the software as described didn't look that complex and the team was confident the errors were to be corrected. After examining the test logs though, the team learned that the problems could be more critical:
	- missing studies;
	- sudden stops and restarts;
	- incomplete transfers that paused with no aparent reason;
	- unsynchronized states: sender stating a completed transfer and reciever accusing otherwise;
	- duplicated studies;
	- duplicated series within studies.

The full test reports can be found in [] (original in portuguese).

As the kick-off approached, the managers were pressured to make a decision between refactoring and rewriting. An agile development process had been choosen and therefore the scope of the first sprint needed to be specified. Then, meetings were held to discuss the issue and a number of questions were raised:
	- How easy is the code to understand and maintain?
	- How well structured is its architecture?
	- How well documented is this software?
	- Which technologies were utilized?
	- Do our team have any expertise on them?
	- How serious are the errors found?
	- Why were the original developers, presumably familiarized with the code, unable to solve them?
	- Do this project classify as bankruptcy or can it be saved?
And the list went on.

However, the team struggled due to lack of information on the project and its source code:
    - no version control history was available;
	- no requirements document or users cases were elicited;
	- the original developers and managers could not be contacted;
	- no risks were assessed.

To summarize, the only reliable source of information were the code itself and the tests report. On that account, a source code inspection took place.

It was obvious that there was no certainty about whether the program's malfunctions could be fixed in a reasonable amount of time. If they could be, then fixing them would have been the better choice. Otherwise, the team might have found themselves trapped trying to refactor an unfeasible codebase. On one hand, it seemed inefficient to let the original software go to waste. On the other hand, the refactoring effort could backfire and end up consuming more time and energy. It was a trade-off situation. A decision had to be made to maximize the probability of success, based on the project's objective and subjective qualities, and the severity of the reported errors.

Although, because of the best guidelines were unfamiliar to the managers, the decision was made to split the difference. The development team was divided in two pairs of programmers, named Brownfield and Greenfield. The first group was responsible for trying to fix the old software, while the later was in charge of starting a new project to rewrite the program.

The plan was to pick the best alternative after 6 sprints and abandon the less promising one. By choosing this strategy the managers accepted a certain loss in productivity in exchange of postponing the decision to the future when they should have more information. This was more of a practical decision than an empirically supported one.

After 4 sprints of no progress it was a clear failure for the Brownfield team.


[...]


STATEMENT OF THE PROBLEM

First of all, 

How to make the best choice between trying to fix and rewriting a problematic software, considering risks involved in both alternatives?

The issue the team faced was to decide on the spot 

This is similar (but not quite the same) to the maintenance x replacement problem, which has been vastly studied []. This research field aims to decide when it isn't worth any longer to maintain a legacy software and therefore rebuilding the software is a better solution. As time passes, a legacy software becomes increasingly more difficult (and costly) to maintain due to many factors, including technical debts acumulation and outdated technologies []. However, rewriting raises its own concerns and risks, specially regarding costs and schedule overruns []. Many researchers have tried to find the sweet spot, the optiomal time to freeze the old project evolution and start working on the new one.

As more enhancements are performed, these systems deteriorate and become more expensive to maintain. Such systems are often termed legacy software systems (Keith 1995)

Maintenance activities in software systems are broadly characterized as a sequence of corrective, adaptive, and perfective actions (Swanson 1976)

However similar, this problem differs to the this research topic on some aspects. First, the problematic software isn't exactly a legacy, as crucial bugs prevented it from going into production. Second, fixing is just one kind of maintenance (corrective). And finally, not much time has passed since the software has been written, so it isn't a matter of outdated technology. Nevertheless, the options are the same: the existing code can only be evolved or abandoned. And once a decision is made and the man-hour is spent, going back is costly.


SIGNIFICANCE OF THE RESEARCH

As will be demonstrated below, there is a scarcity of studies addressing this specific problem, despite its potential significance in decision-making.

In the case under examination, practitioners opted for a middle-ground approach: the team divided into two groups, one dedicated to understanding the flaws in the existing program, while the other initiated a new project solely based on the requirements. The result was that the first group failed to resolve the issues with the original project within the allocated timeframe, leading to the termination of the Brownfield branch.

In essence, the task was completed. The team made efforts to rectify the old program, failed to make any progress, and moved forward. However, this decision was evidently suboptimal. It's clear that the chosen path was a compromise rather than a systematic approach.

Therefore, the objective of this case study is to ascertain whether there objectively existed a better decision to be made in that scenario, based on evidence from the literature. This endeavor may yield guidelines for future reference.


METHODOLOGY

To accomplished this research goal a number of steps were needed.

1- Organize all data the practioners had available on the project, technologies, scope and contexts that could have influenced the decision making;
2- Gather evidence from the literature on that subject;
3- Apply those evidences on the case studied to assess if there was objectivly an optimal (or better) decision to be made.

Each of those steps bear their on challenges. First, the data used must reflect exactly what the practioners had available. Second, a methodology was needed to gather literature evidences. To cover that, we choose to run a Rapid Review. A RR is usually choosen over a traditional systematic review for being more flexible and less time consuming, while still providing a controlled process of obtaining sufficient evidence on the research question []. Adittionally, we'll use snowballing backwards on the discovering step to stretch our data set.

Snowballing refers to a sampling method used in literature reviews. This approach is employed to identify relevant research papers on a particular topic. The idea is to start with a small set of known or highly relevant papers and then use them as a "snowball" to find additional relevant sources by examining their references and citations. This particular combination of using Google Scholar to put up a initial set and snowballing hass been empirically supported [https://www.sciencedirect.com/science/article/pii/S0950584922000659, https://dl.acm.org/doi/abs/10.1145/3266237.3266240].

Finally, applying theoretical evidence to a concrete case might be tricky and bias susceptible. First, it's important to aknowledge that the solo researcher of the present work was part of the development team, although not responsible for the managerial decisions.


RAPID REVIEW PROTOCOL

1. PRACTICAL PROBLEM

A company has reported critical issues with its recently developed software. A new team is formed and faces the decision between fixing the software or rewriting it from scratch.


2. RESEARCH QUESTIONS

How can the best choice between fixing and rewriting problematic software be made, considering the risks associated with both alternatives?

Additional secondary questions may aid in answering the main question by addressing similar trade-offs:

- How can critical technical debt, major software risks, or even software bankruptcy (defined as software failure beyond repair) in a software project be detected?

	Identifying these elements may help prevent wasting time and resources on code that is unfeasible to fix.

- How does software complexity affect its maintainability?

	High complexity or entanglement may indicate poor maintainability.

- How can the decision between maintaining a legacy system and replacing it be made?

	The factors that lead to abandoning a legacy system may also apply to a buggy software that is beyond repair.

It's important to note that the secondary questions are evaluated only in the context of answering the main question.


3. METHOD

To gather relevant evidence to answer these research questions, the following steps are proposed:
	- Conduct an open search on Google Scholar to discover relevant keywords on the topic.
	- Construct a search query from the articles found.
	- Run the query on the same platform. Relevant articles linked to one of the research questions are freely harvested to constitute an initial dataset.
	- Execute backward snowballing to collect related works that match the selection criteria.
	- Review all the final dataset for evidence that directly addresses the main research questions or indirectly through one of the secondary questions.
	- Report the findings along with their applicability to the case studied.


4. SEARCH STRATEGY

- Source

Google scholar.

- Initial search query

software ((project (failure OR bankruptcy OR "thecnical debt")) OR (problem rewrite (refactoring OR refactor)) OR (risks maintenance decision))


5. SELECTION PROCEDURE

There will be accepted only studies that match all the following criteria:
	- papers published in journals or conferences;
	- written in english;
	- available on Google Scholar;
	- with title and/or abstract that addresses at least one of the research questions.

The selection process will be executed by one researcher in one round and documented into a spreadsheet.


6. QUALITY ASSESSMENT

No quality assessment will be made on the selected studies.


7. EXTRACTION PROCEDURE

A spreadsheet will be created to store the evidences found that answer the research questions.


8. SYNTHESIS PROCEDURE

The synthesys procedure will be based on the principles of narrative synthesis. The key findings will be collected and sequenced into a spreadsheet and then synthesized into a coherent narrative that addresses the research question or objectives. This may involve summarizing key themes, discussing commonalities and discrepancies, and providing interpretations or explanations for the observed patterns.


9. REVIEW REPORT

The findings will be reported in the Discussions session through evidence briefings, presented in a storytelling narrative format.


RAPID REVIEW REPORT AND DISCUSSIONS

This report aims to provide a succinct overview of evidences on how to choose between fixing and replacing a software with severe problems. The review investigates the several studies present in the RR final dataset and synthesizes key findings, challenges and recommendations for practitioners and researchers in the field.


KEY FINDINGS



DISCUSSION


Whenever problems appear on a software one usually have three options: doing nothing (ignore), making incremental changes (refactor), or writing a new program from scratch (rewrite). Although, this statement is valid only when the problems are small enough that can be ignored. [1]

To make a decision, it seemed inexorable to assess the success/failure chances of the poject based on historical events.

The search for factors that influence project success or failure has been of great interest to both researchers and practitioners. One stream of work is focused on developing decision rules and/or decision support systems to aid in making systematic decisions on whether projects should be terminated [16-the-causes-of-project-failure]

Current approaches to the software process make it too easy for projects to make high-risk commitments that they will later regret: The code-driven, evolutionary development process model tempts people to say, “Here are some neat ideas I’d like to put into this system. I’ll code them up, and if they don’t fit other people’s ideas, we’ll just evolve things until they work.” This sort of approach usually works fine in some well-supported minidomains like spreadsheet applications but, in more complex application domains, it most often creates or neglects unsalvageable high-risk elements and leads the project down the path to disaster. [15-software-risk-management-principles-and-]
Software project failure is not a rare event. In fact....

If you define failure as the total abandonment of a project before or shortly after it is delivered [4-why-software-fails].

The distinction between functional complexity and system quality is important because rewriting a software system will improve its quality but will not reduce its functional complexity [12-an-economic-model-to-estimate-rewrite]

According to [311], maintenance requests can be classified into: 1) adaptive, 2) perfective, and 3) corrective. In our study, we focus on adaptive and perfective maintenance requests. Not a good fit. [12-an-economic-model-to-estimate-rewrite.pdf]

Most models focus on adaptive and perfective changes and make assumptions like the rate of maintenance requests arrival [12, 13]

The channeling of communication via parameter-passing rather than global variables is characteristic of more maintainable programs. Thus, the stability measures indicate that the stability of programs utilizing parameter passing is generally better than that of programs utilizing global variables. [11-some-stability-measures-for-software-maintenance]

Software maintenance is defined as the performance of those activities required to keep a software system operational and responsive after it is accepted and placed into production [10]. Maintenance activities can be divided into three categories: corrective, adaptive, and perfective. Whereas corrective maintenance refers to changes usually triggered by a failure of the software detected during operation, adaptive and perfective maintenance refer to changes due to external changes. Adaptive maintenance is initiated by changes of-the operational environment; perfective maintenance is initiated by changes of the requirements. ... Erroneously reported failures may be due to inappropriate documentation or differences between the specified and user-expected function of a software system; as a consequence, perfective maintenance activities can be triggered. ... 1) Maintainability: Is the average effort in staff-hours per maintenance task different? 2) Comprehensibility: Is the average isolation effort (effort to decide what to change) in staff-hours per maintenance task, or the average amount of rework (all effort spent for changing already existing documents such as requirements, designs, code, or test plans) per system unit as a percent of all effort spent per unit throughout the lifecycle different? 3) Locality: Is the average number of changed units per maintenance task, or the average maximum portion of the change effort spent in one single unit per maintenance task different? 4) Modifiability: Is the average correction effort in staff-hours per maintenance task and unit different? 5) Reusability: Is the average amount of reused documentation as a percent of all documentation per maintenance task' different? [10-a-controlled-expeniment-on-the-impact-of-]

Once a particular maintenance objective is established, the maintenance personnel must first understand what they are to modify. They must then modify the program to satisfy the maintenance objectives. After modification, they must ensure that the modification does not affect other portions of the program. Finally, they must test the program. These activities can be accomplished in the four phases as shown in Fig. 1. The first phase consists of analyzing the program in order to understand it. Several attributes such as the complexity of the program, the documentation, and the self-descriptiveness of the program contribute to the ease of understanding the program. The complexity of the program is a measure of the effort required to understand the program and is usually based on the control or data flow of the program. The self-descriptiveness of the program is a measure of how clear the program is, i.e., how easy it is to read, understand, and use. The second phase consists of generating a particular maintenance proposal to accomplish the implementation of the maintenance objective. This requires a clear understanding of both the maintenance objective and the program to be modified. The third phase consists of accounting for all of the ripple effect as a consequence of programn modifications. In software, the effect of a modification may not be local to the modification, but may also affect other portions of the program.

complexity metrics: KLOC, number of variables, number of interfaces, number of different logical paths [11]

To analyze software complexity metrics has shown to be less effective because of lacking history of the studied project. Most of the studies try to relate . For example, [9-the-use-of-software-complexity-Metrics-], examines the changes on complexity from one version to the next of a given system.

As we don't have access to the versions backlog of this project, nor do we know pretty much anything about its previous history, we don't have a baseline to estimate code refactoring and bug fixing activities.

In using these metrics, it is important to distinguish between the computational and psychological complexity of software, since the reasons for assessing them differ. Computational complexity refers to "the quantitative aspects of the solutions to computational problems" [15], such as comparing the efficiency of alternate algorithmic solutions. For example, as the number of distinct control paths through a program increases, the computational complexity may increase. Psychological complexity refers to characteristics of software which make it difficult to understand and work with.

a program with many control paths could be psychologically simple if any regularity existed in the program's branching process.

are part of an ongoing research program investigating human factors in software engineering.

These experiments were designed to investigate factors which influence two aspects of the software maintenance process; namely, understanding an existing program (Experiment 1) and accurately implementing modifications to it (Experiment 2). These factors included structured programming techniques, program documentation, and software complexity. [8-measuring-the-psychological-complexity-of-software-maintenance]

Developing software systems is an expensive, and often a difficult process as software development projects are affected by a series of problems, such as poor project management, cost and schedule overruns, poor quality software and under-motivated developers [1], [3]. Boehm suggested in 1991 that realistic schedule and budgets together with a continuing steam of changes in requirements are high risk factors for software development projects [2]. The Standish Group indicated in 1994 that approximately 31% of corporate software development projects are cancelled before completion and 53% cost nearly 200% of their original estimate [18]. Glass called challenged projects "runaway projects" when he discussed 16 project disasters in 1998 [6]. He found that the failed projects he reviewed were mostly huge, and that the failure factors were not just management factors but also included technical factors. Linberg, in 1999, found that 20% ofsoftware projects failed, and that 46% experienced cost and schedule overruns or significantly reduced functionality [12]. Glass revisited failed projects in 2002 and found that poor estimation was high on his list of failure factors [7]. He suggested that we do estimation very badly and that most of our estimates are more like wishes than realistic targets [7]. To make matters worse, we seem to have no idea how to improve on these bad practices. The result is an impossible estimation target, with shortcuts taken, and good practices skipped. "The evil twin of optimistic estimation", and "unstable requirements" result from customers and users only having a vague idea of the required solution at the outset of a project when initial estimates need to be done [8]. Naturally this makes it difficult for estimators and developers. It is commonly accepted that requirements change throughout a project and the system's life cycle. Managing these changes becomes a challenge [7]. Other studies, suggest various failure rates for software development projects up to 85% [10]. In 2006 the Standish Group suggested that 67% ofIT projects fail or are challenged (cited in [15]). In 2007 Sauer et. al. [17] suggest that the situation is not so bad and in fact 67% of the projects they investigated in the UK delivered close to budget, schedule and scope expectations. Recently Charette noted that "billions of dollars are wasted each year on failed software projects" and that "we have a dismal history of projects that have gone awry" [4], Charette provides a long list of high profile failed projects from around the world in his "Hall of Shame" and suggests that from 5%-15% of projects will be abandoned before or shortly after delivery as hopelessly inadequate [4]. Most IT experts agree that such failures occur far more often than they should. (/7-what-factors-lead-to-software-project-failure.pdf)

Bankruptcy of a software project is defined as the status. That is acompanied with heavy financial damage and/or loss of reputation by not meeting the target date or an excess over the budget by approximately 20%. [6-an-analysis-of-software-project-failure]

There are two kinds of bankruptcy as mentioned before: One is caused by an expenditure over the budget. The other involves not meeting the target date.  [6-an-analysis-of-software-project-failure] (the case have met both) This study proposes a methodology to determine software bankruptcy by ploting a graph comparing the development and testing progresses and the number of bugs found. ...  The number of items that the check have not been carried out and the number of bugs detected versus the number of working days elapsed.


CONCLUSION

Software projects will always call for trade-off decisions because of human factors and non-deterministic events that lead to not fully predictable results.

When faced with the fixing x rewriting dilemma, all the practioner can do is to investigate the current stage of the project, apply the best guidelines available, make the decision and hope for the best.

In the case presented, we demonstraded that, with the on-hand information, opting for rewriting would've been the less risky scenario, hypothesis that would've saved the team time and resources.

Further research might try to quantify each aspects and risks associated with the problematic software to propose an stochastic indicator and a thresshold, to decide more objectivly the path that minimize the probability of failure.
