INTRODUCTION

Frequently, a software development project requires crucial decisions at the outset that might heavily influence its success. The challenge lies in the timing of these initial decisions, as they take place when the team has the least information about the context, scope and risks involved, insights that will be better collected later on.

This study presents a case in which a development team was tasked with resuming a previous project that had failed in the past. Significant bugs were discovered, which the original developers were unable to fix. The new team was provided with the source code and some initial requirements, and they had to decide whether attempting to fix those bugs or rewriting the entire program from scratch.

What factors should they have considered? What would've been the best decision? Was there an objective decision to be made? These are the questions we endeavor to answer.


BACKGROUND

This section presents a brief explanation of the studied project and the challenges faced. The following description is a summarization extracted from the Requirements Document produced in partnership with the sponsors.


UPLOADER

Uploader is a codename for the studied case that we are using so forth. It consist of an application to share medical images between hospitals and clinics using the DICOM protocol over the internet. It should allow users to set routes between nodes to which the studies are automatically and safely sent. Its final goal is to make exams images available accross many points, wherever the doctors, technichians and patients need them.

Each LAN wether inside a hospital, clinic or diagnosing center could have Uploader installed in a centralized host (aka Gateway), which is reponsible for recieving DICOM studies produced in many modalities such as Magnetic Resonance Imaging (MRI), X-Rays machines and Computed Tomography Scanners (CT scan). The Gateway's job is simply forwarding the studies to the next connected Gateway. It must not store locally the studies for longer than strictly needed to make sure that all connected recipiants have received them. Also, all the connected Gateways need to establish a secure channel to exchange the files between them (a VPN), since sensitive data will travel through the internet.

After recieving studies from a neighbor Gateway, it's optional (can be configured) to also forward the studies to a local PACS (Picture Archiving and Communication System), using the DICOM protocol, in order to persist them and/or to integrate with other DICOM applications. Any DICOM compatible software can be used for that purpose, such as Orthanc and DCM4Chee.

The main user of Uploader is often the Hospital's Network Manager who would authenticate, setup the Gateways and local PACS and connect them using a graphical user interface, monitor the health of the network and eventually consult transfer logs.

Other minor requirements have also been described but they are less relevant to this case study. The full Requirements Document can be found in [] (original in portuguese, anonymized).

Each Gateway is composed of three components:
- Uploader T (transmitter): responsible for sending studies to the next peer.
- Uploader R (receiver): receives the incoming studies and stores them in the local PACS, if one is configured.
- Uploader M (manager): can be used to configure 'T' and 'R' and also to monitor the network and the status of the transfers.

Those three programs make up to 37 thousand lines of code (KLOC), which, accordingly to [https://www.sciencedirect.com/science/article/abs/pii/0164121293900726], makes it a Medium-Large software project. The code is primarly written in Elixir, but other languages such as Java, Shell, Javascript and Python were used. The source code is proprietary and could not be disclosed.


THE CASE

At first glance, the software did not seem very complex, and the team was confident that the errors could be corrected. However, after examining the test logs, the team discovered that the problems were more critical:
- Missing studies;
- Sudden stops and restarts;
- Incomplete transfers that paused for no apparent reason;
- Unsynchronized states, with the sender indicating a completed transfer while the receiver reporting otherwise;
- Duplicated studies;
- Duplicated series within studies.

The full Test Reports can be found in [] (original in portuguese, anonymized).

As the kick-off approached, the managers felt pressured to decide between refactoring and rewriting. An agile development process had been chosen, so the scope of the first sprint needed to be specified. Meetings were held to discuss the issue and several questions were raised:
- How easy is the code to understand and maintain?
- How well structured is its architecture?
- How well documented is the software?
- Which technologies were utilized?
- Does our team have any expertise with them?
- How serious are the errors found?
- Why were the original developers, presumably familiar with the code, unable to solve those issues?
- Can this project be classified as failure (or bankruptcy)?

However, the team struggled due to lack of information about the project's previous history:
- No version control was available;
- No requirements document or user cases were elicited;
- The original developemnt team could not be contacted;
- No risks were assessed or monitored.

To summarize, the only reliable source of information were the code itself and the tests reports. On that account, a source code inspection took place. By then it was obvious that there was no certainty about whether the program's malfunctions could be fixed in a reasonable amount of time. If they could be, then this probably would've been the better choice. Otherwise, the team might have found themselves trapped trying to refactor an unfeasible codebase. On the one hand, it seemed inefficient to let the original software go to waste, but on the other hand, the refactoring effort could end up consuming more time and energy. It was clearly a trade-off situation. A decision had to be made to maximize the probability of success, based on the project's objective and subjective qualities, and the severity of the reported errors.

Although, because the best guidelines weren't available, the managers decide to split the difference. The development team was divided in two pairs of programmers, named Brownfield and Greenfield. The first group was responsible for trying to fix the old software, while the later was in charge of starting a new project to rewrite the program. The plan was to pick the best alternative after 6 sprints and abandon the less promising one. By choosing this strategy the managers accepted a certain loss in productivity in exchange of postponing the decision to the future when they should had more information. This was more of a practical decision than an empirically supported one.

The timeline of the table 1 shows how the sprints played out for the entire project. As it can be seen, after 4 sprints of no progress, it was determined that the Brownfield failed and this branch was terminated prematurely. The team reported the most critical troubles they've found:
- Low familiarity with the Elixir syntax and logic;
- Lack of documentation, specially Software Requirements, including use cases, and Architecture and API specifications;
- High coupling/Low modularity of components;
- Confusing mix of different programming languages. In some cases, Elixir, Shell and Python codes were combined into a single functionality;
- Potential problems internal to the Erlang/Elixir VM environment causing abrupt crashes;
- Code seemed excessivly large and complex for the intended solution.

[...]


STATEMENT OF THE PROBLEM

The issue here described is similar to the maintenance versus replacement problem, which has been extensively studied. This field of research focuses on determining when it is no longer worthwhile to maintain legacy software and when rebuilding it is a better solution. Over time, maintaining a legacy software becomes increasingly more difficult and time consuming due to factors such as the accumulation of technical debt and outdated technologies. However, rewriting also introduces its own concerns and risks, particularly regarding costs and schedule overruns [2]. Many researchers have attempted to identify the optimal time to cease evolving the old project and start working on a new one. As more enhancements are performed, legacy systems deteriorate and become more expensive to maintain (Keith, 1995). Maintenance activities in software systems are broadly characterized as a sequence of corrective, adaptive, and perfective actions (Swanson, 1976).

Although similar, the problem addressed in this research differs in several key aspects. First, the problematic software is not exactly legacy software, as critical bugs have prevented it from going into production. Second, fixing it falls under a single kind of maintenance: corrective one. Finally, not much time has passed since the software was written, so outdated technology is not a primary concern. Nonetheless, the options remain the same: the existing code can either be evolved or abandoned, and once a decision is made and resources are spent, reversing the decision becomes costly.

The trade-off under analysis can be summarized as follows: How can the best choice between fixing and rewriting problematic software be made, considering the risks associated with both alternatives?


SIGNIFICANCE OF THE RESEARCH

As it will be demonstrated below, there is a scarcity of studies addressing this specific problem, despite its potential significance in decision-making. In the case under examination, practitioners opted for a middle-ground approach, dividing the team in two groups, one dedicated to understanding the flaws in the existing program, while the other initiating a new project solely based on the requirements. The result was that the first group failed to resolve the issues with the original project within the allocated timeframe, leading to the termination of the Brownfield branch.

In essence, the task was completed. The team made efforts to rectify the old program, failed to make any progress, and moved forward. However, this decision was probably suboptimal. Therefore, the objective of this case study is to ascertain whether there objectively existed a better decision to be made in that scenario, based on evidence from the literature. This may yield guidelines for future reference.


METHODOLOGY

To accomplish this research goal a number of steps were needed:
1- Organize all data the practioners had available on the project, technologies, scope and contexts that could have influenced the decision making;
2- Gather evidence from the literature on that subject;
3- Apply those evidences on the case studied to assess if there was a right decision to be made.

Each of those steps beared their on challenges. First, the data used must have reflected exactly what the practioners had available. Second, a methodology was needed to gather literature evidences. To cover that, we choose to run a Rapid Review. A RR is usually choosen over a traditional systematic review when a more flexible and less time consuming methodology is desired, while still providing a controlled process of obtaining sufficient evidence on the research question [].

Adittionally, backwards snowballing on the discovering step was used to stretch the data set. Snowballing refers to a sampling method used in literature reviews. This approach is employed to identify relevant research papers on a particular topic. The idea is to start with a small set of known or highly relevant papers and then use them as a "snowball" to find additional relevant sources by examining their references and citations. This particular combination of using Google Scholar to put up a initial set and snowballing hass been empirically supported [https://www.sciencedirect.com/science/article/pii/S0950584922000659, https://dl.acm.org/doi/abs/10.1145/3266237.3266240].

It is important to recognize though that applying theoretical evidence to a concrete case might be tricky and bias susceptible. It's also important to aknowledge that the solo researcher of the present work was part of the development team, although not responsible for the managerial decisions.


RAPID REVIEW PROTOCOL

PRACTICAL PROBLEM

A company has reported critical issues with its recently developed software. A new team is formed and faces the decision between fixing the software or rewriting it from scratch.


RESEARCH QUESTIONS

How can the best choice between fixing and rewriting problematic software be made, considering the risks associated with both alternatives?

Additional secondary questions might aid in answering the main question by addressing similar trade-offs:

- How can critical technical debt, major software risks and software failure (or bankruptcy) be detected in a software project?

    Identifying these elements may help prevent wasting time and resources on code that is unfeasible to fix.

- How does software complexity affect its maintainability?

    High complexity, entanglement and low modularity may indicate poor maintainability.

- How can the decision between maintaining a legacy system and replacing it be made?

    The factors that lead to abandoning a legacy system may also apply to a buggy software that is beyond repair.

It's important to note that the secondary questions were evaluated only in the context of answering the main question.


METHOD

To gather relevant evidence to answer the research questions, the following steps were proposed:
- Conducting an open search on Google Scholar to discover relevant keywords on the topic.
- Constructing a search query from the articles found.
- Running the query on the same platform. Relevant articles linked to one of the research questions were freely harvested to constitute an initial dataset.
- Executing backward snowballing to collect related works that matched the selection criteria.
- Reviewing the final dataset for evidences that addressed the questions.
- Reporting the findings along with their applicability to the case studied.


SEARCH STRATEGY

Source: Google scholar.

Initial search query: software ((project (failure OR bankruptcy OR "thecnical debt")) OR (problem rewrite (refactoring OR refactor)) OR (risks maintenance decision))


SELECTION PROCEDURE

Only studies matching all the following criteria were accepted:
- papers published in journals or conferences;
- written in english;
- available on Google Scholar;
- with title and/or abstract addressing at least one of the research questions.

The selection process were executed by one researcher in one round and documented in table format.


QUALITY ASSESSMENT

No quality assessment were mande on the selected studies.


SYNTHESIS PROCEDURE

The synthesys procedure was based on the principles of narrative synthesis. The key findings were collected, sequenced and then synthesized into a coherent narrative addressing the research question and objectives. This involved summarizing key themes, discussing commonalities and discrepancies, and providing interpretations or explanations for the observed scenario.


REVIEW REPORT

The findings were reported in the Discussions session through evidence briefings, presented in a storytelling narrative format.


FINAL DATASET

[...]


RAPID REVIEW REPORT AND DISCUSSIONS

This report aims to provide a succinct overview of evidences on how to choose between fixing and replacing a software with severe problems. The review investigates the several studies present in the RR final dataset and synthesizes key findings and recommendations for practitioners and researchers in the field.


KEY FINDINGS

[...]


DISCUSSION

In this section we match the most important aspects of the case studied with the collected evidences.

Deciding whether to fix the existing code or to rewrite it from scratch is a significant decision that depends on various factors. Usually there're three options: doing nothing (ignore), making incremental changes (refactor), or writing a new program from scratch (rewrite). Although, this statement is valid only when the problems are small enough that can be ignored [1]. The first and most obvious conclusion is that ignore was not an option in our case. On the contrary, the presence of many critical errors reported was an indicative of fundamental design flaws [3, 14], which would be confirmed by the detection of entanglement and low modularity [2] in the code inspection.

If fixing the program were the chosen path, it would be necessary to perform a series of maintenance tasks until the software was compliant and coherent. Maintenance can be classified into adaptive, perfective and corrective [12]. In this study, we focused on corrective maintenance, which are usually triggered by a failure of the software detected during tests or operation. Once a particular maintenance objective is established, one must first understand what they are to modify. They must then modify the program to satisfy the maintenance objectives. After modification, they must ensure that the modification does not affect other portions of the program. Finally, they must test the program. The following aspects of a software were found to be important to execute corrective maintenances [10]:
- Maintainability: the average effort in staff-hours per maintenance task;
- Comprehensibility: the average isolation effort (effort to decide what to change) in staff-hours per maintenance task, or the average amount of rework (all effort spent for changing already existing documents such as requirements, designs, code, or test plans) per system unit as a percent of all effort spent per unit throughout the lifecycle;
- Locality: the average number of changed units per maintenance task, or the average maximum portion of the change effort spent in one single unit per maintenance task;
- Modifiability: the average correction effort in staff-hours per maintenance task and unit;
- Reusability: the average amount of reused documentation as a percent of all documentation per maintenance task.

However, without a version tracking, it was challenging to understand the code's history, changes, and the rationale behind them.

The fact that the code was medium-large sized made the decision even harder [1]. One recurrently studied factor of a software is its psychological complexity, which refers to characteristics of the software that make it difficult to understand and work with [12]. There's a large number of complexity metrics, such as KLOC, quantity of variables, interfaces and different logical paths [11]. However, to analyze software complexity metrics objectively, in this particular case, has shown to be less effective because of, once again, lacking of history. Most of the studies try to correlate those metrics with past behavior, for example, to address how hard it is expected to perform a maintenance task in that complex module in comparison with another one [8], or to predict programming times comparing one to the next version of the same software increasingly more complex [9].

Since there was no version backlog and the previous history was unknown, a baseline to estimate code refactoring and bug fixing activities wasn't available. Although, it was reported by the practioners that the code seemed too large for its use case, which is a weaker evidence but does suggests high complexity and leads to harder maintenance [2] and low understandability [11].

Furthermore, the absense of software documentation (specifically requirements, including use cases, and risks management) was a red flag as well, since it is evidence of difficulty to enhance and maintain systems [2, 9] and improved overall risks [7, 15]. That also indicates poor project management (although cannot be confirmed) which have been pointed out as the single greatest cause of software failures [4, 17].

Adittionally, choosing Elixir as main technology was at least questionable, as imature technologies is linked to project failures and threatens maintainability [4, 7]. Well stablished languages like Python, C++, Java and Javascript have over 50 times the usage [https://madnight.github.io/githut] and could be therefore better suited.

To complete the decision, it was also necessary to assess the success/failure chances of the given poject. Software project failure is not a rare event. In fact, it accounts for over at least 30% of the projects [7]. Software Failue can be defined as the total abandonment of a project before or shortly after it is delivered [4], or as a synonym of Software Bankruptcy, when it is acompanied with heavy financial damage and/or loss of reputation by not meeting the target date or an excess over the budget by approximately 20% [6].

The search for factors that influence the project success or failure has been of great interest to both researchers and practitioners. One stream of work is focused on developing decision rules and/or decision support systems to aid in making systematic decisions on whether projects should be terminated [16]. As mentioned, there're two kinds of bankruptcy: expenditure over the budget and not meeting the target date [6]. The studied case fits the later.

Again, the absense of basic planning, design and developemnt documents plays a huge role in improving chances of failure. We found evidence that this Code-Driven development process induces high-risk commitments. It tempts people to say "Here are some neat ideas I'd like to put into this system. I'll code them up, and if they don't fit other people's ideas, we'll just evolve things until they work." This sort of approach usually works fine in some well-supported minidomains but, in more complex application domains, it most often creates or neglects unsalvageable high-risk elements and leads the project down the path to disaster. [15]

To summarize, we verified or presumed the following failure-linked factors reported in the literature [4, 5, 7] in the case studied:
- Inaccurate estimates of needed resources;
- Badly defined requirements;
- Poor reporting of project’s status;
- Unmanaged risks;
- Use of immature technology;
- Inability to handle the project’s complexity;
- Sloppy development practices;
- Poor project management;
- Project under-estimated;
- Risks not re-assessed, controlled, or managed through the project;
- Delivery decision made without adequate requirements information;
- Risk not incorporated into the project plan;
- Change control not monitored, nor dealt with effectively;
- Inappropriate development methodology for the project.

Although we found advice to avoid complete rewrite when the application concerned is large because much of the effort will be expended on redeveloping the initial software functionality [13], the requirements elicited were not large or complex which, again, indicated poor design/implementation and indicated that a better structured code could be easier to understand and maintain. A final thought is that not all requirements elicited were present in the original project, so even if the bugs could be corrected, enhancements would still be needed. In this scenario, a total replacement, although require significant investment, such a rework would also improve consistency and increase familiarity of the code to the developers, which would lower further maintenance costs. To conclude we found reason to believe that rewriting would've been the best option for our specific case.


CONCLUSION

Software projects will always call for trade-off decisions because of human factors and non-deterministic events that lead to not fully predictable results. When faced with the fixing versus rewriting dilemma, all the practioner can do is to investigate the current stage of the project, apply the best guidelines available, make a decision and hope for the best. We propose a breakdown of the most usefull guidelines we found on the literature and that applied to our case:

Severity and Scope of Bugs:
- If the bugs are isolated and the affected module can be specified, fixing may be more efficient.
- If the bugs are pervasive and affect core functionalities, rewriting is most likely necessary.

Code Quality and Maintainability:
- High-quality, well-structured and well-documented codes are easier to fix.
- Poorly written, undocumented and entangled codes are cost-effective to rewrite.

Technical Debt:
- If the software has accumulated technical debt, rewriting can offer a fresh start, reduce maintenance costs and enhance developers familiarity. Those advantages usually pays off.

Time and Resource Constraints:
- Fixing bugs may require less immediate investment compared to rewriting.
- Rewriting can be more time-consuming and resource-intensive but might save time in the long run.

Requirements:
- If the current software struggles to meet all requirements, rewriting can provide a more robust foundation.

Technological Advancements:
- If the existing software relies on outdated or imature technologies, rewriting can leverage modern tools and more tested frameworks.

Team Expertise:
- The availability of skilled developers who are proficient in the existing code is key.
- If developers who can understand quickly the code is scarse, build a new system is time-saving and more effective.

In the case presented, we demonstraded that, with the information available, opting for rewriting would've been the less risky alternative, hypothesis that would've proved to save time and resources.

Although there isn't always a right answer, the proposed checklist could be used to suport decisions alike. Further research might validate that on a broader range of cases and also quantify how those factors individiually weight on the final decision. Finally, an stochastic indicator and a thresshold could be proposed to help deciding in a more objectivly manner.
